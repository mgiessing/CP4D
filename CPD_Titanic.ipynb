{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Data preparation and model training"}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer, LabelEncoder, OneHotEncoder, PowerTransformer\nfrom sklearn.model_selection import train_test_split, KFold\nimport xgboost as xgb\nimport pickle", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_new = df.drop(columns=['Name'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_new.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Could also use sth. like LabelEncoder...\ndf_new['Sex'] = pd.get_dummies(df_new['Sex'])\n\n#LabelEncoder\n#le = LabelEncoder()\n#le.fit_transform(df_new['Sex'])\ndf_new.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#X=df_new[['Pclass', 'Sex', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']].to_numpy()\nX=df_new.drop(columns=['Survived']).to_numpy()\ny=df_new['Survived'].to_numpy()\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(X)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(X_scaled)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)\nall_results = {}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Decisiontree classifiers & Random Forest"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n\nclf = DecisionTreeClassifier(random_state=1)\nclf = clf.fit(x_train, y_train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(\"Test data: \",clf.score(x_test, y_test))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import cross_val_score\nclf = DecisionTreeClassifier()\nscores = cross_val_score(clf, X_scaled, y, cv=10)\nprint(\"CV mean: \", scores.mean())\n\nall_results['Decision Tree'] = scores.mean()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier\nest = RandomForestClassifier(n_estimators=10)\nest.fit(x_train, y_train)\nest.score(x_test, y_test)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "clf = RandomForestClassifier(n_estimators=10)\nscores = cross_val_score(clf, X_scaled, y, cv=10)\nprint(\"CV mean: \", scores.mean())\n\nall_results['Random Forest'] = scores.mean()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Boosting classifier (XGBoost)"}, {"metadata": {}, "cell_type": "code", "source": "%%time\nfrom xgboost.sklearn import XGBClassifier, DMatrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n#parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\nparameters = {'n_estimators': [x for x in range(5, 11, 5)], 'max_depth':[x for x in range(1,4)], 'learning_rate': [round(x, 2) for x in np.arange(0.01, 0.11, 0.01)]}\nxgb = XGBClassifier()\nclf = GridSearchCV(xgb, parameters, cv=10)\nclf.fit(X_scaled, y)\n#print(clf.best_estimator_)\nprint(clf.best_score_)\nall_results['XG Boost'] = clf.best_score_\n#xgb = XGBClassifier(n_estimators=10, max_depth=1, learning_rate=0.1, objective='binary:logistic')\n#cv_scores = cross_val_score(xgb, scaled, labels, cv=10)\n#print(cv_scores.mean())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Support Vector Machines (SVMs)"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import svm\nfrom sklearn.pipeline import Pipeline\n\nKERNELS = ['linear', 'poly', 'rbf', 'sigmoid']\nfor kernel in KERNELS:\n    svc = svm.SVC(kernel=kernel, C=1.0)#.fit(x_train, y_train)\n    cv_scores = cross_val_score(svc, X_scaled, y, cv=10)\n    print(\"Kernel: {}, accuracy: {}\".format(kernel, cv_scores.mean()))\n    all_results[str('SVM-'+ kernel)] = cv_scores.mean()\n    \nsvc = svm.SVC(kernel='rbf', C=1.0)\npipeline = Pipeline([('scaler', scaler), ('svc', svc)])\nmodel = pipeline.fit(x_train, y_train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## K-nearest-neighbors (KNN)"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.neighbors import KNeighborsClassifier\nd = {}\nfor i in range(1,50):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    cv_scores = cross_val_score(knn, X_scaled, y, cv=10)\n    d[str(i)]=cv_scores.mean()\n    \nmax_key = max(d, key=d.get)\nprint(\"Best K: {} with accuracy: {}\".format(max_key, d[max_key]))\nall_results[str('KNN-'+max_key)] = d[max_key]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Logistic Regression"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\ncv_scores = cross_val_score(lr, X_scaled, y, cv=10)\nprint(cv_scores.mean())\nall_results['Logistic Regression'] = cv_scores.mean()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Which algorithm performed best...?"}, {"metadata": {}, "cell_type": "code", "source": "max_key = max(all_results, key=all_results.get)\nprint(\"Best Algorithm: {} with an accuracy of: {:.2f}\".format(max_key, all_results[max_key]))\nprint(\"\\nSee the full results here:\\n\")\nfor key, value in sorted(all_results.items(), reverse=True, key=lambda item: item[1]):\n    print(\"%s: %s\" % (key, value))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# --------------------"}, {"metadata": {}, "cell_type": "markdown", "source": "# Deploying a model"}, {"metadata": {}, "cell_type": "markdown", "source": "## After training a model we can make it usable on our cluster in 3 steps:\n#### (Log in if necessary)\n#### 1.) Create a space or use an existing\n#### 2.) Create a model repository or use an existing\n#### 3.) Create a model deployment or use an existing"}, {"metadata": {}, "cell_type": "code", "source": "###\n# Beim CP4Dv3.0.1 sollte eigentlich watson-machine-learning-client-V4 vorinstalliert sein und es sollte alles \"problemlos\" funktionieren!\n# Falls es dennoch Probleme geben sollte, mal \"vorsichtshalber\" alles deinstallieren und nur V4 installieren...\n# WICHTIG: Falls irgendwas uninstalled oder neuinstalled wurde den Jupyter Kernel neustarten!\n###\n\n#!pip uninstall watson-machine-learning-client-V4 -y\n#!pip uninstall watson-machine-learning-client -y\n#!pip uninstall ibm-watson-machine-learning -y\n#!pip install watson-machine-learning-client-V4", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Option 1 - Curl:\n#!curl -k -X GET https://zen-cpd-zen.apps.edb-bde1.cecc.ihost.com/v1/preauth/validateAuth -u admin:password\n\n#Option 2 - Python requests:\nimport requests, json\nfrom requests.auth import HTTPBasicAuth\n\ns = requests.Session()\nres = s.get('https://zen-cpd-zen.apps.edb-b59f.cecc.ihost.com/v1/preauth/validateAuth', auth=HTTPBasicAuth('admin', 'password'), verify=False)\nres = json.loads(res.text)\ntoken = res['accessToken']\nprint(token)", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "wml_credentials = {\n    \"token\": token,\n    \"instance_id\" : \"wml_local\",\n    \"url\"         : \"https://zen-cpd-zen.apps.edb-b59f.cecc.ihost.com\",\n    \"version\": \"3.0.1\"\n}\n\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient\nclient = WatsonMachineLearningAPIClient(wml_credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## List and/or create space"}, {"metadata": {}, "cell_type": "code", "source": "client.spaces.list()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "if not client.spaces.get_details():\n    print(\"Create resources!\")\n    space_details = client.spaces.store(meta_props={client.spaces.ConfigurationMetaNames.NAME: \"dev_space2\"})\n    space_id = client.spaces.get_uid(space_details)\nelse:\n    print(\"Resource vorhanden!\")\n    for sp in client.spaces.get_details()['resources']:\n        print(sp,\"\\n\")\n    print(\"Using '{}' as default space\".format(client.spaces.get_details()['resources'][0]['metadata']['name']))\n    space_id = client.spaces.get_details()['resources'][0]['metadata']['id']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Liste der zugeh\u00f6rigen Algorithmus ID ausgeben lassen...\n# client.software_specifications.list()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## List or create model repository"}, {"metadata": {}, "cell_type": "code", "source": "#TODO: Warnungen unterdr\u00fccken, da es sonst etwas verwirrend ist...\n\nif not client.repository.get_details()['models']['resources']:\n    print(\"Publish model...\")\n    software_spec_uid = client.software_specifications.get_uid_by_name(\"scikit-learn_0.22-py3.6\")\n    model_props = {\n        client.repository.ModelMetaNames.NAME: \"Titanic Survivor Prediction\",\n        client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.22\",\n        client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n        client.repository.ModelMetaNames.INPUT_DATA_SCHEMA: [{'id': '1',\n                                                                    'type': 'ndarray',\n                                                                     'fields': [{'name': 'Pclass', 'type': 'float'},\n                                                                                {'name': 'Sex', 'type': 'float'},\n                                                                                {'name': 'Age', 'type': 'float'},\n                                                                                {'name': 'Siblings/Spouses Aboard', 'type': 'float'},\n                                                                                {'name': 'Parents/Children Aboard', 'type': 'float'},\n                                                                                {'name': 'Fare', 'type': 'float'}]\n                                                                       }]\n    }\n    published_model = client.repository.store_model(model=model, pipeline=pipeline, meta_props=model_props, training_data=x_train, training_target=y_train)\nelse:\n    print(\"Model found!\")\n    print(\"Using default model {}\".format(client.repository.get_details()['models']['resources'][0]['metadata']['name']))\n    published_model = client.repository.get_details()['models']['resources'][0]\n\n# Optional: Delete by (gu)id\n#client.repository.delete('b6591272-ee24-40a7-841b-d7e8846277d2')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import json\npublished_model_uid = client.repository.get_model_uid(published_model)\nmodel_details = client.repository.get_details(published_model_uid)\nprint(json.dumps(model_details, indent=2))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "loaded_model = client.repository.load(published_model_uid)\nprint(loaded_model)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "loaded_model.score(x_test, y_test)\n#test_predictions = loaded_model.predict(x_test).transform(x_test)\n#test_predictions.select('probability', 'predictedLabel').show(n=3, truncate=False)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## List or create deployment"}, {"metadata": {}, "cell_type": "code", "source": "client.deployments.list()\n# Optional: Delete deployment\n# client.deployments.delete('70a57b43-3a4c-41ce-81e0-fdcf3a6116b1')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "if not client.deployments.get_details()['resources']:\n    print(\"Create deployment...\")\n    meta_props = {\n        client.deployments.ConfigurationMetaNames.NAME: \"Titanic Survivor Prediction\",\n        client.deployments.ConfigurationMetaNames.SPACE_UID: space_id,\n        client.deployments.ConfigurationMetaNames.ONLINE: {}\n    }\n\n    created_deployment = client.deployments.create(artifact_uid=published_model_uid, meta_props=meta_props, name=\"Titanic Survivor Prediction\")\nelse:\n    print(\"Deployment found!\")\n    print(\"Using default deployment: '{}' \".format(client.deployments.get_details()['resources'][0]['entity']['name']))\n    created_deployment = client.deployments.get_details()['resources'][0]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "scoring_endpoint = client.deployments.get_scoring_href(created_deployment)\ndeployment_id = created_deployment.get(\"metadata\").get(\"id\")\nprint(f'Scoring endpoint is available at: {scoring_endpoint}')\nprint(f'Deployment ID is: {deployment_id}')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Prepare scoring payload.\njob_payload = {\n    client.deployments.ScoringMetaNames.INPUT_DATA: [{\n        'values': [list(x_test[-1])]\n    }]\n}\nprint(job_payload)\n\nX_scaled = scaler.fit_transform(X)\nscaler.inverse_transform(x_test[-3])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Perform prediction and display the result.\njob_details = client.deployments.score('61d07f78-fa96-4da2-b987-bbd1240d2d8c', job_payload)\nprint(job_details)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's try our deployed model and see it in action!"}, {"metadata": {}, "cell_type": "markdown", "source": "### First let's create two passengers:\nP1 which had a 3rd class ticket(3), was a male (0), 22 years old, had 1 sibling aboard, no parents or childrens aboard and paid 8.25 GBP for his ticket<br>\n--> Very similar datapoint to people who actually did NOT survive (0)...let's see<br><br>\nP2 which had a 1st class ticket(1), was a female (1), 38 years old, had 1 sibling aboard, no parents or childrens aboard and paid 70.5 GBP for her ticket<br>\n--> Very similar datapoint to people actually DID survive (1) ... let's see"}, {"metadata": {}, "cell_type": "code", "source": "###Spielwiese:\n#(Survieved)->Pclass\tSex\tAge\tSiblings/Spouses Aboard\tParents/Children Aboard\tFare\n\n#0\t3\t0\t22.0\t1\t0\t7.2500\n#Hat nicht \u00fcberlebt\nPassagier1 = [3, 0, 22., 1, 0 , 8.25]\n\n#1\t1\t1\t38.0\t1\t0\t71.2833\n#Hat \u00fcberlebt\nPassagier2 = [1, 1, 38., 1, 0 , 70.5]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Scale the data using the scaler that was fit&transformed on the trainingsdata. Here we just need to transform data to our scaler using .transform()"}, {"metadata": {}, "cell_type": "code", "source": "# Komischerweise wird der Scaler im Pipeline Codesegment nochmal angepasst, daher muss der hier \"reinitialisiert\" werden\nX_scaled = scaler.fit_transform(X)\n\nscaled_pass = scaler.transform([Passagier1, Passagier2])\nscaled_pass", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Create the payload that we will send to our model"}, {"metadata": {}, "cell_type": "code", "source": "payload = {client.deployments.ScoringMetaNames.INPUT_DATA: [{\n    'values': scaled_pass\n}]}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "job_details = client.deployments.score(deployment_id, payload)\njob_details", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "As expected the first passenger did not survive while the second (better class, but also paid more) did survive.<br>\nHere a little bit prettified"}, {"metadata": {}, "cell_type": "code", "source": "for idx,num in enumerate(job_details['predictions'][0]['values']):\n    if 0 in num:\n        print(f'Passenger #{idx+1} would not survive')\n    elif 1 in num:\n        print(f'Passenger #{idx+1} would survive')\n    else:\n        print(\"That shouldn't have happened!\")", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}